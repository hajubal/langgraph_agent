{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1cf819",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cb932",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423dec5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b09cb",
   "metadata": {},
   "source": [
    "`(2) 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54412ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67655",
   "metadata": {},
   "source": [
    "## 2. 도구 호출 (Tool Calling)\n",
    "- 도구 호출은 LLM이 특정 작업을 수행하기 위해 외부 기능을 호출하는 기능\n",
    "- 이를 통해 LLM은 외부 API 통합 등 더 복잡한 작업을 수행할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdccc6b",
   "metadata": {},
   "source": [
    "### 2-1. 랭체인 내장 도구\n",
    "- Tavily 웹 검색 도구 (예시)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7e257",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c85ed38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://2.jkamor.com/entry/스테이크와-잘-어울리는-와인-추천', 'content': '스테이크와 잘 어울리는 와인 추천 스테이크와 잘 어울리는 와인 추천 하지만 스테이크와 와인을 어떻게 매칭해야 할지 잘 모르는 분들도 많습니다. 이 글에서는 스테이크와 잘 어울리는 와인을 추천하고, 와인을 선택할 때 고려해야 할 사항을 설명해 드리겠습니다. 지방 함량이 높은 스테이크는 타닌이 풍부한 와인과 잘 어울립니다. 타닌이 적고 산도가 높은 와인과 잘 어울립니다. 추천 와인: 샤르도네, 소비뇽 블랑, 피노 그리지오 타닌이 적당한 와인과 잘 어울립니다. 추천 와인: 까베르네 소비뇽, 메를로, 피노 누아 타닌이 풍부한 와인과 잘 어울립니다. 추천 와인: 까베르네 소비뇽, 메를로, 템프라니요 스테이크와 잘 어울리는 와인의 품종은 다음과 같습니다. 레드 와인:\\xa0까베르네 소비뇽, 메를로, 피노 누아, 쉬라즈, 시라, 템프라니요 화이트 와인:\\xa0샤르도네, 소비뇽 블랑, 피노 그리지오, 리슬링, 게뷔르츠트라미너 이번 글에서 소개해 드린 내용을 참고하여, 스테이크와 잘 어울리는 와인을 선택해 보시기 바랍니다.'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'url': 'https://www.wineandnews.com/ko/ranking/10-perfect-wine-pairing-with-swiss-steak', 'content': '스위스 스테이크와 완벽한 와인 페어링 10가지 스위스 스테이크와 어울리는 10가지 와인 페어링을 살펴보세요. 이 시칠리아 와인은 스위스 스테이크의 풍부한 맛과 밝은 균형을 이루며 요리의 미묘한 맛을 강조합니다. 1. 스위스 스테이크와 가장 잘 어울리는 레드 와인은 무엇인가요? 스위스 스테이크와 가장 잘 어울리는 레드 와인은 탄닌과 산미가 균형 잡힌 미디엄 바디 레드 와인입니다. 와인의 산도는 요리의 풍부하고 풍성한 맛을 잘 살려주기 때문에 스위스 스테이크와 페어링할 때 중요합니다. 1. 스위스 스테이크와 가장 잘 어울리는 레드 와인은 무엇인가요? 랭킹 에그 샐러드의 품격을 높여주는 와인 10가지: 한입에 어울리는 완벽한 와인 10가지 * Aug 18, 2024 * ∙ * 3 에그 샐러드와 어울리는 10가지 와인 페어링을 살펴보고, 소비뇽 블랑과 스파클링 와인 등 이 요리의 크리미하고 톡 쏘는 풍미를 더욱 돋보이게 하는 와인을 골라보세요.'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# 검색할 쿼리 설정\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 2개의 결과 반환)\n",
    "web_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# 웹 검색 실행\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in search_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6791575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자료형: \n",
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "tavily_search_results_json\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('A search engine optimized for comprehensive, accurate, and trusted results. '\n",
      " 'Useful for when you need to answer questions about current events. Input '\n",
      " 'should be a search query.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input for the Tavily tool.',\n",
      " 'properties': {'query': {'description': 'search query to look up',\n",
      "                          'title': 'Query',\n",
      "                          'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'TavilyInput',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(web_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(web_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(web_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(web_search.args_schema.model_json_schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b600d9",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51a3633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 웹 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17d2468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 82, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-9804e4ea-4e00-4e0c-9977-274a6aa57715-0', usage_metadata={'input_tokens': 82, 'output_tokens': 11, 'total_tokens': 93})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'안녕하세요! 어떻게 도와드릴까요?'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 도구 호출이 필요 없는 LLM 호출을 수행\n",
    "query = \"안녕하세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd8df009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GiIrXVPh3p38m0SDLsO5Tli8', 'function': {'arguments': '{\"query\":\"스테이크와 어울리는 와인 추천\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 91, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-975bf137-219d-4bb2-a9ec-a8cb96eaa190-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '스테이크와 어울리는 와인 추천'}, 'id': 'call_GiIrXVPh3p38m0SDLsO5Tli8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 91, 'output_tokens': 27, 'total_tokens': 118})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "''\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'args': {'query': '스테이크와 어울리는 와인 추천'},\n",
      "  'id': 'call_GiIrXVPh3p38m0SDLsO5Tli8',\n",
      "  'name': 'tavily_search_results_json',\n",
      "  'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84d0d45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_search_results_json',\n",
       " 'args': {'query': '스테이크와 어울리는 와인 추천'},\n",
       " 'id': 'call_GiIrXVPh3p38m0SDLsO5Tli8',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = ai_msg.tool_calls[0]\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86835305",
   "metadata": {},
   "source": [
    "`(3) 도구(tool) 실행하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 방법 1: 직접 도구 호출 처리\n",
    "\n",
    "# 이 방법은 AI 메시지에서 첫 번째 도구 호출을 가져와 직접 처리한다.\n",
    "# 'args'를 사용하여 도구를 호출하고 결과를 얻는다.\n",
    "\n",
    "tool_output = web_search.invoke(tool_call[\"args\"])\n",
    "print(f\"{tool_call['name']} 호출 결과:\")\n",
    "print(\"-\" * 100)\n",
    "print(tool_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa17109",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 방법 2: ToolMessage 객체 생성\n",
    "\n",
    "# 이 방법은 도구 호출 결과를 사용하여 ToolMessage 객체를 생성한다.\n",
    "# 도구 호출의 ID와 이름을 포함하여 더 구조화된 메시지를 만든다.\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_output,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"]\n",
    ")\n",
    "\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 방법 3: 도구 직접 호출하여 바로 ToolMessage 객체 생성\n",
    "\n",
    "# 이 방법은 도구를 직접 호출하여 ToolMessage 객체를 생성한다.\n",
    "# 가장 간단하고 직관적인 방법으로, LangChain의 추상화를 활용한다.\n",
    "\n",
    "tool_message = web_search.invoke(tool_call)\n",
    "\n",
    "print(tool_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tool_message.tool_call_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01309400",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tool_message.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e71c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 실행 - 도구 호출이 여러 개인 경우\n",
    "\n",
    "# tool_messages = web_search.batch([tool_call])\n",
    "\n",
    "tool_messages = web_search.batch(ai_msg.tool_calls)\n",
    "\n",
    "print(tool_messages)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20257ba",
   "metadata": {},
   "source": [
    "`(4) ToolMessage를 LLM에 전달하여 답변을 생성하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5de654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = web_search_chain.invoke(\"오늘 모엣샹동 샴페인의 가격은 얼마인가요?\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f49a9f",
   "metadata": {},
   "source": [
    "### 2-2. 사용자 정의 도구\n",
    "- @tool decorator를 통해 사용자 정의 도구를 정의할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c058ff5",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2647393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224eddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_web))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_web.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_web.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_web.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37117ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "search_result = search_web.invoke(query)\n",
    "\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcda933",
   "metadata": {},
   "source": [
    "`(2) LLM 도구 호출 성능 비교하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf539df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 기본 LLM\n",
    "llm_gemini_flash = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "llm_gemini_pro = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "llm_groq = ChatGroq(model=\"llama3-groq-70b-8192-tool-use-preview\", temperature=0)\n",
    "\n",
    "# LLM에 도구 바인딩하여 추가 \n",
    "tools=[search_web]\n",
    "\n",
    "gemini_flash_with_tools = llm_gemini_flash.bind_tools(tools)\n",
    "gemini_pro_with_tools = llm_gemini_pro.bind_tools(tools)\n",
    "groq_llama3_with_tools = llm_groq.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f29ab",
   "metadata": {},
   "source": [
    "- gemini-1.5-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faceb0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = gemini_flash_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f69b933",
   "metadata": {},
   "source": [
    "- gemini-1.5-pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = gemini_pro_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d19ee",
   "metadata": {},
   "source": [
    "- llama3-groq-70b-8192-tool-use-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36366e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = groq_llama3_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d5144",
   "metadata": {},
   "source": [
    "### 2-3. Runnable 객체를 도구(tool) 변환\n",
    "- 문자열이나 dict 입력을 받는 Runnable을 도구로 변환\n",
    "- as_tool 메서드를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea96cf",
   "metadata": {},
   "source": [
    "`(1) Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하는 함수 \n",
    "def search_wiki(input_data: dict) -> List[Document]:\n",
    "    \"\"\"Search Wikipedia documents based on user input (query) and return k documents\"\"\"\n",
    "    query = input_data[\"query\"]\n",
    "    k = input_data.get(\"k\", 2)  \n",
    "    wiki_loader = WikipediaLoader(query=query, load_max_docs=k, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    return wiki_docs\n",
    "\n",
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSearchSchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "    k: int = Field(2, description=\"The number of documents to return (default is 2)\")\n",
    "\n",
    "# RunnableLambda 함수를 사용하여 위키피디아 문서 로더를 Runnable로 변환 \n",
    "runnable = RunnableLambda(search_wiki)\n",
    "wiki_search = runnable.as_tool(\n",
    "    name=\"wiki_search\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a specified number of documents. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSearchSchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ff3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위키 검색 실행\n",
    "query = \"파스타의 유래\"\n",
    "wiki_results = wiki_search.invoke({\"query\":query})\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in wiki_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b812a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web, wiki_search])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06d2ed",
   "metadata": {},
   "source": [
    "`(2) LCEL 체인`\n",
    "- 위키피디아 문서를 검색하고 내용을 요약하는 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하고 텍스트로 반환하는 함수 \n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs =[\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "        ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# 요약 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")\n",
    "\n",
    "# LLM 및 요약 체인 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm | StrOutputParser() \n",
    ")\n",
    "\n",
    "# 요약 테스트 \n",
    "summarized_text = summary_chain.invoke({\"query\":\"파스타의 유래\"})\n",
    "pprint(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "# as_tool 메소드를 사용하여 도구 객체로 변환\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_summary))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_summary.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_summary.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_summary.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78824759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web, wiki_summary])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg.tool_calls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 실행 \n",
    "tool_message = wiki_summary.invoke(ai_msg.tool_calls[1])\n",
    "\n",
    "print(tool_message)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2de1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[wiki_summary])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def wiki_summary_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = wiki_summary.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = wiki_summary_chain.invoke(\"파스타의 유래에 대해서 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f828547",
   "metadata": {},
   "source": [
    "### 2-4. 벡터저장소 검색기\n",
    "- @tool decorator 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9dc12",
   "metadata": {},
   "source": [
    "`(1) 문서 로드 및 인덱싱`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# 메뉴판 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# 문서 분할 (Chunking)\n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "    메뉴 항목을 분리하는 함수 \n",
    "    \"\"\"\n",
    "    # 정규표현식 정의 \n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "    \n",
    "    # 각 메뉴 항목을 Document 객체로 변환\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "        \n",
    "        # 새로운 Document 객체 생성\n",
    "        menu_doc = Document(\n",
    "            page_content=item.strip(),\n",
    "            metadata={\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    \n",
    "    return menu_documents\n",
    "\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Vectorstore를 사용하기 위한 준비\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3\") \n",
    "\n",
    "# Chroma 인덱스 생성\n",
    "menu_db = Chroma.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# Retriever 생성\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "# 쿼리 테스트\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요?\"\n",
    "docs = menu_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf58d36",
   "metadata": {},
   "source": [
    "- 와인 메뉴에 대해서도 같은 작업을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc82b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인 메뉴 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")\n",
    "\n",
    "\n",
    "# Chroma 인덱스 생성\n",
    "wine_db = Chroma.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "wine_retriever = wine_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "docs = wine_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040915b",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소 로드\n",
    "menu_db = Chroma(\n",
    "    embedding_function=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_menu(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_menu))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_menu.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_menu.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_menu.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 벡터 저장소 로드\n",
    "wine_db = Chroma(\n",
    "   embedding_function=embeddings_model,   \n",
    "   collection_name=\"restaurant_wine\",\n",
    "   persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_wine(query: str) -> List[Document]:\n",
    "   \"\"\"\n",
    "   Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "   Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "   \"\"\"\n",
    "   docs = wine_db.similarity_search(query, k=2)\n",
    "   if len(docs) > 0:\n",
    "      return docs\n",
    "   \n",
    "   return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_wine))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_wine.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_wine.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_wine.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b74a1",
   "metadata": {},
   "source": [
    "`(3) 여러 개의 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_web, wiki_summary, search_wine, search_menu]\n",
    "for tool in tools:\n",
    "    print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 4개의 검색 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"파스타 메뉴가 있나요? 이 음식의 역사 또는 유래를 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b78e3",
   "metadata": {},
   "source": [
    "## 3. Few-shot 프롬프팅 \n",
    "- 각 도구의 용도를 구분하여 few-shot 예제로 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3e6b9",
   "metadata": {},
   "source": [
    "### 3-1. Few-shot 도구 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd743c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"트러플 리조또의 가격과 특징, 그리고 어울리는 와인에 대해 알려주세요.\", name=\"example_user\"),\n",
    "    AIMessage(\"메뉴 정보를 검색하고, 위키피디아에서 추가 정보를 찾은 후, 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_menu\", \"args\": {\"query\": \"트러플 리조또\"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\"트러플 리조또: 가격 ₩28,000, 이탈리아 카나롤리 쌀 사용, 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리\", tool_call_id=\"1\"),\n",
    "    AIMessage(\"트러플 리조또의 가격은 ₩28,000이며, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 이제 추가 정보를 위키피디아에서 찾아보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \"트러플 리조또\", \"k\": 1}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"트러플 리조또는 이탈리아 요리의 대표적인 리조또 요리 중 하나로, 고급 식재료인 트러플을 사용하여 만든 크리미한 쌀 요리입니다. 주로 아르보리오나 카나롤리 등의 쌀을 사용하며, 트러플 오일이나 생 트러플을 넣어 조리합니다. 리조또 특유의 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 것이 특징입니다.\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"트러플 리조또의 특징에 대해 알아보았습니다. 이제 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_wine\", \"args\": {\"query\": \"트러플 리조또에 어울리는 와인\"}, \"id\": \"3\"}]),\n",
    "    ToolMessage(\"트러플 리조또와 잘 어울리는 와인으로는 주로 중간 바디의 화이트 와인이 추천됩니다. 1. 샤르도네: 버터와 오크향이 트러플의 풍미를 보완합니다. 2. 피노 그리지오: 산뜻한 산미가 리조또의 크리미함과 균형을 이룹니다. 3. 베르나차: 이탈리아 토스카나 지방의 화이트 와인으로, 미네랄리티가 트러플과 잘 어울립니다.\", tool_call_id=\"3\"),\n",
    "    AIMessage(\"트러플 리조또(₩28,000)는 이탈리아의 대표적인 리조또 요리 중 하나로, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 주요 특징으로는 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 점입니다. 고급 식재료인 트러플을 사용해 풍부한 맛과 향을 내며, 주로 아르보리오나 카나롤리 등의 쌀을 사용합니다. 트러플 리조또와 잘 어울리는 와인으로는 중간 바디의 화이트 와인이 추천됩니다. 특히 버터와 오크향이 트러플의 풍미를 보완하는 샤르도네, 산뜻한 산미로 리조또의 크리미함과 균형을 이루는 피노 그리지오, 그리고 미네랄리티가 트러플과 잘 어울리는 이탈리아 토스카나 지방의 베르나차 등이 좋은 선택이 될 수 있습니다.\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    *examples,\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f10c84",
   "metadata": {},
   "source": [
    "### 3-2. 답변 생성 체인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system + f\"Today's date is {today}.\"),\n",
    "    *examples,\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return fewshot_search_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11927ed4",
   "metadata": {},
   "source": [
    "## 4. LangChain Agent 사용\n",
    "- 유의사항: 프롬프트에 \"agent_scratchpad\",  \"input\" 변수를 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7127af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dedent(\"\"\"\n",
    "        You are an AI assistant providing restaurant menu information and general food-related knowledge. \n",
    "        Your main goal is to provide accurate information and effective recommendations to users.\n",
    "\n",
    "        Key guidelines:\n",
    "        1. For restaurant menu information, use the search_menu tool. This tool provides details on menu items, including prices, ingredients, and cooking methods.\n",
    "        2. For general food information, history, and cultural background, utilize the wiki_summary tool.\n",
    "        3. For wine recommendations or food and wine pairing information, use the search_wine tool.\n",
    "        4. If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "        5. Provide clear and concise responses based on the search results.\n",
    "        6. If a question is ambiguous or lacks necessary information, politely ask for clarification.\n",
    "        7. Always maintain a helpful and professional tone.\n",
    "        8. When providing menu information, describe in the order of price, main ingredients, and distinctive cooking methods.\n",
    "        9. When making recommendations, briefly explain the reasons.\n",
    "        10. Maintain a conversational, chatbot-like style in your final responses. Be friendly, engaging, and natural in your communication.\n",
    "\n",
    "\n",
    "        Remember, understand the purpose of each tool accurately and use them in appropriate situations. \n",
    "        Combine the tools to provide the most comprehensive and accurate answers to user queries. \n",
    "        Always strive to provide the most current and accurate information.\n",
    "        \"\"\")),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3dad12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool calling Agent 생성\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "tools = [search_web, wiki_summary, search_wine, search_menu]\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# AgentExecutor 생성 \n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd37cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentExecutor 실행\n",
    "\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "agent_response = agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(agent_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb411fca",
   "metadata": {},
   "source": [
    "## 5. Gradio 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "        # agent_executor를 사용하여 응답 생성\n",
    "        response = agent_executor.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": chat_history[-2:]    # 최근 2개의 메시지 기록만을 활용 \n",
    "        })\n",
    "        \n",
    "        # agent_executor의 응답에서 최종 답변 추출\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 알리고 로그 기록\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "# 예제 질문 정의\n",
    "example_questions = [\n",
    "    \"시그니처 스테이크의 가격과 특징을 알려주세요.\",\n",
    "    \"트러플 리조또와 잘 어울리는 와인을 추천해주세요.\",\n",
    "    \"해산물 파스타의 주요 재료는 무엇인가요? 서울 강남 지역에 레스토랑을 추천해주세요.\",\n",
    "    \"채식주의자를 위한 메뉴 옵션이 있나요?\"\n",
    "]\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# 데모 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd26485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb837bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-agent-n22hjchf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
